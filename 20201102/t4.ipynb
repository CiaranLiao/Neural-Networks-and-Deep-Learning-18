{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]), array([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"iris.txt\", header=None)\n",
    "x = df.iloc[0:150, [0,1,2,3]].values\n",
    "y = df.iloc[0:150, [4]].values\n",
    "\n",
    "y = np.where(y == 'Iris-setosa', 1, 0)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.vstack((x[0:40], x[50:90], x[100:140]))\n",
    "y_train = np.vstack((y[0:40], y[50:90], y[100:140]))\n",
    "\n",
    "x_test = np.vstack((x[40:50], x[90:100], x[140:150]))\n",
    "y_test = np.vstack((y[40:50], y[90:100], y[140:150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def costfunction(X, y, w):\n",
    "    cost = 0\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    w = np.array(w)\n",
    "    size = y.shape[0]\n",
    "    for i in range(size):\n",
    "        if y[i] == 1:\n",
    "            cost -= np.log(sigmoid(np.dot(X[i], w.T)))\n",
    "        else:\n",
    "            cost -= np.log(1 - sigmoid(np.dot(X[i], w.T)))\n",
    "    return cost / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGD(X, y, w=1, alpha=0.8, n_iter=10000, eta=0.05):\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    w = np.ones(x.shape[1]+1) * w\n",
    "    size = y.shape[0]\n",
    "\n",
    "    X = np.column_stack((X, np.ones(size).T))\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        temp = costfunction(X, y, w)\n",
    "        w = w - alpha * (np.dot((sigmoid(np.dot(X, w.T)).reshape(size, 1) - y).T, X)) / size\n",
    "        if i % 100 == 0:\n",
    "            print('Loss is: ', costfunction(X,y,w), w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:  [5.22453988] [[-2.3686422  -0.53065034 -1.64665923  0.10933446  0.46667174]]\n",
      "Loss is:  [0.00538067] [[ 0.18691639  2.19545617 -3.00871814 -0.71219222  1.14305246]]\n",
      "Loss is:  [0.00341633] [[ 0.2440487   2.3918372  -3.31009848 -0.85608549  1.17874431]]\n",
      "Loss is:  [0.00252082] [[ 0.28209292  2.5253452  -3.51435561 -0.95403911  1.20277069]]\n",
      "Loss is:  [0.00200494] [[ 0.31065929  2.62699006 -3.6695179  -1.02869358  1.22093781]]\n",
      "Loss is:  [0.00166828] [[ 0.33354082  2.70925588 -3.79487828 -1.08916712  1.23556421]]\n",
      "Loss is:  [0.00143072] [[ 0.35262873  2.7784528  -3.90017184 -1.14007082  1.24781488]]\n",
      "Loss is:  [0.00125382] [[ 0.36900367  2.83822415 -3.99101153 -1.18406828  1.25835924]]\n",
      "Loss is:  [0.00111682] [[ 0.38334154  2.89086799 -4.0709336  -1.22284042  1.2676179 ]]\n",
      "Loss is:  [0.00100749] [[ 0.39609339  2.93792878 -4.14231217 -1.25751743  1.27587256]]\n",
      "Loss is:  [0.00091815] [[ 0.4075753   2.98049533 -4.20681942 -1.2888964   1.28332122]]\n",
      "Loss is:  [0.00084374] [[ 0.41801734  3.0193645  -4.26567819 -1.31756094  1.29010842]]\n",
      "Loss is:  [0.00078077] [[ 0.42759222  3.05513733 -4.31981007 -1.34395139  1.29634292]]\n",
      "Loss is:  [0.00072677] [[ 0.43643291  3.0882785  -4.36992713 -1.36840832  1.3021086 ]]\n",
      "Loss is:  [0.00067993] [[ 0.44464396  3.11915483 -4.41659107 -1.39120066  1.30747157]]\n",
      "Loss is:  [0.00063892] [[ 0.45230906  3.14806098 -4.46025291 -1.41254453  1.31248482]]\n",
      "Loss is:  [0.00060269] [[ 0.45949627  3.17523733 -4.50128032 -1.43261624  1.31719151]]\n",
      "Loss is:  [0.00057044] [[ 0.46626163  3.20088254 -4.53997701 -1.45156159  1.32162725]]\n",
      "Loss is:  [0.00054156] [[ 0.4726519   3.2251627  -4.57659681 -1.46950249  1.32582178]]\n",
      "Loss is:  [0.00051553] [[ 0.47870646  3.24821813 -4.61135403 -1.48654195  1.32980017]]\n",
      "Loss is:  [0.00049195] [[ 0.4844588   3.27016844 -4.6444313  -1.50276782  1.33358378]]\n",
      "Loss is:  [0.00047048] [[ 0.48993763  3.29111645 -4.67598551 -1.51825562  1.33719093]]\n",
      "Loss is:  [0.00045085] [[ 0.49516776  3.31115115 -4.70615247 -1.53307075  1.34063748]]\n",
      "Loss is:  [0.00043284] [[ 0.50017076  3.33035016 -4.7350505  -1.54727022  1.34393722]]\n",
      "Loss is:  [0.00041624] [[ 0.50496553  3.34878152 -4.76278334 -1.56090406  1.34710225]]\n",
      "Loss is:  [0.00040091] [[ 0.5095687   3.36650526 -4.78944247 -1.5740164   1.35014322]]\n",
      "Loss is:  [0.00038668] [[ 0.51399496  3.38357457 -4.81510893 -1.58664635  1.35306957]]\n",
      "Loss is:  [0.00037346] [[ 0.51825741  3.40003684 -4.83985488 -1.59882877  1.35588968]]\n",
      "Loss is:  [0.00036113] [[ 0.52236772  3.41593447 -4.86374488 -1.61059484  1.35861107]]\n",
      "Loss is:  [0.00034962] [[ 0.52633636  3.43130552 -4.88683686 -1.62197257  1.36124046]]\n",
      "Loss is:  [0.00033883] [[ 0.53017277  3.44618434 -4.90918305 -1.63298721  1.36378392]]\n",
      "Loss is:  [0.0003287] [[ 0.53388546  3.46060196 -4.93083072 -1.64366163  1.36624694]]\n",
      "Loss is:  [0.00031917] [[ 0.53748215  3.47458659 -4.95182271 -1.65401657  1.36863447]]\n",
      "Loss is:  [0.0003102] [[ 0.54096987  3.48816389 -4.97219807 -1.66407094  1.37095106]]\n",
      "Loss is:  [0.00030172] [[ 0.54435501  3.5013573  -4.99199241 -1.67384198  1.37320083]]\n",
      "Loss is:  [0.00029371] [[ 0.54764343  3.51418828 -5.01123835 -1.6833455   1.37538754]]\n",
      "Loss is:  [0.00028613] [[ 0.5508405   3.52667653 -5.02996581 -1.69259601  1.37751468]]\n",
      "Loss is:  [0.00027893] [[ 0.55395114  3.53884018 -5.04820234 -1.70160687  1.37958543]]\n",
      "Loss is:  [0.0002721] [[ 0.5569799   3.55069594 -5.06597332 -1.71039038  1.38160272]]\n",
      "Loss is:  [0.0002656] [[ 0.55993097  3.56225927 -5.0833022  -1.71895793  1.38356926]]\n",
      "Loss is:  [0.00025941] [[ 0.56280824  3.57354447 -5.1002107  -1.72732007  1.38548757]]\n",
      "Loss is:  [0.00025351] [[ 0.56561529  3.58456482 -5.11671899 -1.73548657  1.38735998]]\n",
      "Loss is:  [0.00024788] [[ 0.56835548  3.59533267 -5.13284578 -1.74346655  1.38918864]]\n",
      "Loss is:  [0.0002425] [[ 0.57103191  3.60585952 -5.14860853 -1.75126846  1.39097557]]\n",
      "Loss is:  [0.00023735] [[ 0.57364747  3.61615608 -5.16402349 -1.75890023  1.39272265]]\n",
      "Loss is:  [0.00023242] [[ 0.57620486  3.62623238 -5.17910586 -1.76636923  1.39443163]]\n",
      "Loss is:  [0.0002277] [[ 0.57870661  3.63609779 -5.19386985 -1.77368238  1.39610416]]\n",
      "Loss is:  [0.00022317] [[ 0.5811551   3.6457611  -5.20832879 -1.78084616  1.39774175]]\n",
      "Loss is:  [0.00021882] [[ 0.58355252  3.65523056 -5.22249517 -1.78786664  1.39934587]]\n",
      "Loss is:  [0.00021464] [[ 0.58590098  3.66451391 -5.23638073 -1.79474956  1.40091785]]\n",
      "Loss is:  [0.00021062] [[ 0.58820242  3.67361844 -5.24999652 -1.80150027  1.40245897]]\n",
      "Loss is:  [0.00020675] [[ 0.59045869  3.68255102 -5.26335294 -1.80812385  1.40397044]]\n",
      "Loss is:  [0.00020303] [[ 0.59267152  3.69131813 -5.2764598  -1.81462508  1.40545337]]\n",
      "Loss is:  [0.00019944] [[ 0.59484256  3.69992588 -5.28932636 -1.82100847  1.40690884]]\n",
      "Loss is:  [0.00019598] [[ 0.59697334  3.70838005 -5.30196138 -1.82727828  1.40833784]]\n",
      "Loss is:  [0.00019263] [[ 0.59906534  3.71668612 -5.31437314 -1.83343855  1.40974135]]\n",
      "Loss is:  [0.00018941] [[ 0.60111993  3.72484926 -5.32656947 -1.83949311  1.41112024]]\n",
      "Loss is:  [0.00018629] [[ 0.60313843  3.73287439 -5.33855782 -1.84544558  1.41247539]]\n",
      "Loss is:  [0.00018327] [[ 0.60512208  3.74076617 -5.35034524 -1.85129941  1.4138076 ]]\n",
      "Loss is:  [0.00018036] [[ 0.60707207  3.74852903 -5.36193843 -1.85705786  1.41511764]]\n",
      "Loss is:  [0.00017753] [[ 0.6089895   3.75616717 -5.37334376 -1.86272404  1.41640624]]\n",
      "Loss is:  [0.0001748] [[ 0.61087546  3.76368461 -5.38456729 -1.86830091  1.4176741 ]]\n",
      "Loss is:  [0.00017215] [[ 0.61273096  3.77108516 -5.39561479 -1.87379128  1.41892189]]\n",
      "Loss is:  [0.00016958] [[ 0.61455696  3.77837246 -5.40649175 -1.87919785  1.42015022]]\n",
      "Loss is:  [0.00016709] [[ 0.61635438  3.78554997 -5.41720343 -1.88452317  1.42135971]]\n",
      "Loss is:  [0.00016467] [[ 0.6181241   3.792621   -5.42775483 -1.88976969  1.42255093]]\n",
      "Loss is:  [0.00016233] [[ 0.61986697  3.79958872 -5.43815072 -1.89493974  1.42372442]]\n",
      "Loss is:  [0.00016005] [[ 0.62158378  3.80645615 -5.44839567 -1.90003555  1.42488072]]\n",
      "Loss is:  [0.00015783] [[ 0.6232753   3.81322618 -5.45849406 -1.90505927  1.42602032]]\n",
      "Loss is:  [0.00015568] [[ 0.62494226  3.81990157 -5.46845006 -1.91001293  1.42714369]]\n",
      "Loss is:  [0.00015359] [[ 0.62658537  3.82648498 -5.47826768 -1.91489849  1.42825131]]\n",
      "Loss is:  [0.00015155] [[ 0.62820529  3.83297894 -5.48795075 -1.91971783  1.42934361]]\n",
      "Loss is:  [0.00014957] [[ 0.62980268  3.83938589 -5.49750296 -1.92447275  1.430421  ]]\n",
      "Loss is:  [0.00014764] [[ 0.63137814  3.84570818 -5.50692783 -1.92916498  1.43148391]]\n",
      "Loss is:  [0.00014576] [[ 0.63293227  3.85194803 -5.51622874 -1.93379617  1.4325327 ]]\n",
      "Loss is:  [0.00014392] [[ 0.63446563  3.85810761 -5.52540896 -1.93836792  1.43356776]]\n",
      "Loss is:  [0.00014214] [[ 0.63597878  3.86418898 -5.53447162 -1.94288175  1.43458945]]\n",
      "Loss is:  [0.0001404] [[ 0.63747225  3.87019414 -5.5434197  -1.94733914  1.4355981 ]]\n",
      "Loss is:  [0.0001387] [[ 0.63894652  3.87612501 -5.55225612 -1.9517415   1.43659405]]\n",
      "Loss is:  [0.00013704] [[ 0.6404021   3.88198342 -5.56098365 -1.95609021  1.43757762]]\n",
      "Loss is:  [0.00013543] [[ 0.64183944  3.88777116 -5.56960496 -1.96038656  1.43854911]]\n",
      "Loss is:  [0.00013385] [[ 0.643259    3.89348993 -5.57812266 -1.96463182  1.43950883]]\n",
      "Loss is:  [0.00013231] [[ 0.64466121  3.89914139 -5.58653921 -1.96882723  1.44045704]]\n",
      "Loss is:  [0.00013081] [[ 0.64604649  3.90472712 -5.59485703 -1.97297394  1.44139403]]\n",
      "Loss is:  [0.00012934] [[ 0.64741525  3.91024865 -5.60307842 -1.97707309  1.44232007]]\n",
      "Loss is:  [0.0001279] [[ 0.64876786  3.91570748 -5.61120563 -1.98112579  1.4432354 ]]\n",
      "Loss is:  [0.00012649] [[ 0.65010472  3.92110503 -5.6192408  -1.98513309  1.44414028]]\n",
      "Loss is:  [0.00012512] [[ 0.65142617  3.92644268 -5.62718602 -1.989096    1.44503494]]\n",
      "Loss is:  [0.00012378] [[ 0.65273257  3.93172176 -5.63504331 -1.99301552  1.44591962]]\n",
      "Loss is:  [0.00012246] [[ 0.65402425  3.93694357 -5.6428146  -1.9968926   1.44679453]]\n",
      "Loss is:  [0.00012118] [[ 0.65530156  3.94210936 -5.65050179 -2.00072817  1.44765989]]\n",
      "Loss is:  [0.00011992] [[ 0.65656479  3.94722032 -5.65810669 -2.00452311  1.4485159 ]]\n",
      "Loss is:  [0.00011869] [[ 0.65781426  3.95227764 -5.66563107 -2.0082783   1.44936278]]\n",
      "Loss is:  [0.00011748] [[ 0.65905026  3.95728244 -5.67307663 -2.01199456  1.45020071]]\n",
      "Loss is:  [0.0001163] [[ 0.66027308  3.96223583 -5.68044502 -2.01567272  1.45102988]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is:  [0.00011514] [[ 0.661483    3.96713885 -5.68773784 -2.01931355  1.45185048]]\n",
      "Loss is:  [0.00011401] [[ 0.66268028  3.97199254 -5.69495664 -2.02291781  1.45266268]]\n",
      "Loss is:  [0.0001129] [[ 0.66386519  3.97679789 -5.70210293 -2.02648626  1.45346665]]\n",
      "Loss is:  [0.00011181] [[ 0.66503797  3.98155589 -5.70917816 -2.03001959  1.45426256]]\n",
      "Loss is:  [0.00011074] [[ 0.66619888  3.98626745 -5.71618375 -2.03351851  1.45505058]]\n",
      "[[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]] [[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Perfectly matched\n"
     ]
    }
   ],
   "source": [
    "vecw = BGD(x_train, y_train)\n",
    "x_test = np.column_stack((x_test, np.ones(30).T))\n",
    "y_test_cal = sigmoid(np.dot(x_test, vecw.T))\n",
    "y_test_cal = np.where(y_test_cal >= 0.5, 1, 0)\n",
    "print(y_test_cal.T, y_test.T)\n",
    "\n",
    "if (y_test_cal.T == y_test.T).all():\n",
    "    print('Perfectly matched')\n",
    "else:\n",
    "    print('Test set doesnt matches trained vector')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
